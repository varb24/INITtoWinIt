import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB1
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model

# Load the EfficientNetB1 pre-trained model (weights from ImageNet)
base_model = EfficientNetB1(include_top=False, weights='imagenet', input_shape=(224, 224, 3))

# Add a GlobalAveragePooling2D layer to reduce the spatial dimensions of the output
x = base_model.output
x = GlobalAveragePooling2D()(x)

# Add a fully connected layer with 128 neurons and ReLU activation
x = Dense(128, activation='relu')(x)

# Add a final fully connected layer with softmax activation for classification
predictions = Dense(num_classes, activation='softmax')(x)

# Combine the base model and the fully connected layers into a single model
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the weights of the base model layers to prevent overfitting
for layer in base_model.layers:
    layer.trainable = False

# Compile the model with categorical cross-entropy loss and Adam optimizer
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
